<html><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252">
<title>COMS E6998: Machine Learning for Natural Language Processing</title>
</head>
<body link="77BED2" vlink="77BED2" text="D5E1DD" bgcolor="2B3E42" alink="77BED2">

<!-- <body bgcolor="616536" text="1B1112" link="A4E666" vlink="A4E666"
      alink="A4E666"> -->


<p></p><center>
<h2>COMS E6998: Machine Learning for Natural Language Processing
  (Spring 2012) </h2>
</center>
<hr>

<p>
</p><table cols="2">
<tbody><tr><td valign="top" align="center" width="10%">
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/index.html">Home</a> <br><br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures.html">Lectures</a> <br><br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/projects.html">Projects</a> <br><br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/psets.html">Problem sets</a> <br><br>
<!-- <a href="http://courses.csail.mit.edu/6.867/recitations.html">Recitations</a> <br><br>
<a href="http://courses.csail.mit.edu/6.867/projects.html">Projects</a> <br><br>
<a href="http://courses.csail.mit.edu/6.867/problemsets.html">Problem sets</a> <br><br>
<a href="http://courses.csail.mit.edu/6.867/exams.html">Exams</a> <br><br>
<a href="http://courses.csail.mit.edu/6.867/references.html">References</a> <br><br>
<a href="http://courses.csail.mit.edu/6.867/matlab.html">Matlab</a> -->
</td>
<td valign="top" width="85%">

<h2>Lectures:</h2>

<p>

<table text="1B1112" link="A4E666" vlink="A4E666" alink="A4E666" cellspacing="0" cellpadding="5" bgcolor="717546" border="0" width="800">
<tbody><tr> 
<td valign="middle" width="70"><b><u>Date</u></b></td>
<td valign="middle" width="250"><b><u>Lecture</u></b></td>
<td valign="middle" width="200"><b><u>Notes etc</u></b></td>
</tr>

<tr bgcolor="616536"><td valign="middle"> Wed. January 18th</td>
<td valign="middle"><b> Lecture 1:</b> Introduction, hidden Markov models, the perceptron
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec1.1.pdf">Introduction</a>,
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec1.2.pdf">HMMs</a>,
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec1.3.pdf">the perceptron</a>.
<p>
Background reading: 
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/nlp2011/notes/hmms.pdf">
Notes on HMMs</a> from COMS 4705, Fall 2011.

</p><p>In addition,
Jurafsky and Martin Chapter 5 gives useful background on part-of-speech tagging.
</p></td>
</tr>
<tr bgcolor="717546"><td valign="middle">Wed. January 25th</td>
<td valign="middle"><b> Lecture 2: SVMs, Pegasos, Log-linear models (part 1)</b> 
</td><td valign="middle">
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec2.2.pdf">Slides on SVMs</a>,<br>
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec2.3.pdf">Slides on Pegasos</a>,<br>
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec2.4.pdf">Slides on log-linear models (part 1)</a>
<!--  <a href="lectures/lec2.part2.pdf">Slides part 2</a>
  (disciminative dependency parsing) -->
<p>
<b>Background reading:</b>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/perc.converge.pdf">
note on convergence proof for the perceptron
</a>
</p></td>

</tr>
<tr bgcolor="616536"><td valign="middle"> Wed. February 1st</td>
<td valign="middle"><b> Lecture 3:</b> Log-linear models, MEMMs, CRFs
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec3.1.pdf">Slides</a>

<p>Required reading:<br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/loglinear.pdf">
Note on log-linear models, MEMMs, CRFs
</a>



</p><p>
Background reading (optional; gives additional detail on log-linear models): 
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/loglinear.2011.pdf">
Notes on Log-linear models</a> from COMS 4705, Fall 2011.

</p></td>
</tr>
<tr bgcolor="717546"><td valign="middle"> Wed. February 8th</td>
<td valign="middle"><b> Lecture 4:</b> CRFs (continued), discriminative 
dependency parsing
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec4.1.pdf">Slides</a>

<p>Required reading:<br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/fb.pdf">
Note on the forward-backward algorithm
</a>


</p></td>
</tr>
<tr bgcolor="616536"><td valign="middle"> Wed. February 15th</td>
<td valign="middle"><b> Lecture 5:</b> Dependency parsing (continued), 
the structured perceptron, structured Pegasos, discriminative context-free
parsing
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec5.1.pdf">Structured perceptron</a>,
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec5.2.pdf">discriminative CFGs</a>

<p>
(See last lecture slides for dependency parsing. Notes on structured
Pegasos to be posted soon.)

</p><p>
Background reading (optional; gives additional detail on context-free grammars): 
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/pcfgs.pdf">
Notes on probabilistics context-free grammars</a> from COMS 4705, Fall 2011.

</p></td>
</tr>
<tr bgcolor="717546"><td valign="middle"> Wed. February 22nd</td>
<td valign="middle"><b> Lecture 6:</b> 
Naive Bayes Model, the EM Algorithm
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec6.1.pdf">Slides part 1</a>,
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec6.2.pdf">Slides part 2</a>.

(Note that Gaussian mixture models (GMMs), and EM for GMMs, will
be covered on Feb. 29th)

</td>
</tr>
<tr bgcolor="616536"><td valign="middle"> Wed. February 29th</td>
<td valign="middle"><b> Lecture 7:</b> The EM Algorithm (continued), 
Gaussian mixture models, EM for HMMs
</td>
<td valign="middle">
Slides:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/lec6.3.pdf">EM for HMMs</a>.

(See last lecture slides for slides on GMMs, and EM for GMMs)

</td></tr><tr bgcolor="717546"><td valign="middle"> Wed. March 7th</td>
<td valign="middle"><b> Lecture 8:</b> 
The Inside Outside Algorithm
</td>
<td valign="middle">
Required reading:
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/em.pdf">Note on the EM algorithm</a>,
  <a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/notes/io.pdf">Note on the inside-outside algorithm</a>.

</td>
</tr>

<tr bgcolor="616536"><td valign="middle"> Wed. March 14th</td>
<td valign="middle"><b>Spring Break</b> 
</td>
<td valign="middle">
</td>
</tr>

<tr bgcolor="717546"><td valign="middle"> Wed. March 21st</td>
<td valign="middle"><b> Lecture 9:</b> Dual decomposition and
Lagrangian Relaxation
</td>
<td valign="middle">
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/dd.pdf">Slides</a> (we went
as far as the slide titled
"Integrated Constituency and Dependency Parsing: Accuracy").

</td>
</tr>

<tr bgcolor="616536"><td valign="middle"> Wed. March 28th</td>
<td valign="middle"><b>Lecture 10: Dual decomposition and
Lagrangian Relaxation (continued)</b> 
</td>
<td valign="middle">

<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/np.pdf">Slides on non-projective dependency parsing</a>,
<br>

<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/pb.pdf">Slides on phrase-based translation</a>

</td>
</tr>

<tr bgcolor="717546"><td valign="middle"> Wed. April 4th</td>
<td valign="middle"><b> Lecture 11:</b> Phrase-based Translation (continued),
and Cotraining
</td>
<td valign="middle">
For slides on phrase-based translation see the last lecture.
<br>
<a href="http://www.cs.columbia.edu/%7Emcollins/courses/6998-2012/lectures/cotrain.pdf">Slides on cotraining</a>.
</td>
</tr>

<tr bgcolor="616536"><td valign="middle"> Wed. April 11th</td>
<td valign="middle"><b>Lecture 12:</b> 
</td>
<td valign="middle">
</td>
</tr>

<tr bgcolor="717546"><td valign="middle"> Wed. April 18th</td>
<td valign="middle"><b> Lecture 13: Final Exam</b> 
</td>
<td valign="middle">
</td>
</tr>

<tr bgcolor="616536"><td valign="middle"> Wed. April 25th</td>
<td valign="middle"><b>Lecture 14:</b> 
</td>
<td valign="middle">
</td>
</tr>





</tbody></table>



</p></td></tr></tbody></table></body></html>